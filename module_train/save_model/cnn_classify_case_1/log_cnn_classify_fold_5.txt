
model_cnn_classify_fold_5_epoch_0_train_loss_0.5682_macro0.3465_full__0.91_0.07_0.06_test_loss_0.3106_macro0.3463_full__0.96_0.0_0.08
model_cnn_classify_fold_5_epoch_1_train_loss_0.401_macro0.3982_full__0.95_0.05_0.19_test_loss_0.2755_macro0.4392_full__0.96_0.03_0.33
model_cnn_classify_fold_5_epoch_2_train_loss_0.3495_macro0.4371_full__0.95_0.1_0.26_test_loss_0.2626_macro0.476_full__0.96_0.07_0.39
model_cnn_classify_fold_5_epoch_3_train_loss_0.3136_macro0.468_full__0.96_0.1_0.35_test_loss_0.2608_macro0.5273_full__0.96_0.19_0.43
model_cnn_classify_fold_5_epoch_4_train_loss_0.3034_macro0.4842_full__0.96_0.14_0.35_test_loss_0.2597_macro0.5642_full__0.96_0.25_0.48
model_cnn_classify_fold_5_epoch_5_train_loss_0.2799_macro0.4991_full__0.96_0.18_0.36_test_loss_0.2551_macro0.6092_full__0.97_0.34_0.52
model_cnn_classify_fold_5_epoch_6_train_loss_0.2698_macro0.5293_full__0.96_0.2_0.43_test_loss_0.2551_macro0.6183_full__0.97_0.37_0.52
model_cnn_classify_fold_5_epoch_7_train_loss_0.2629_macro0.5393_full__0.96_0.23_0.42_test_loss_0.2464_macro0.6144_full__0.97_0.37_0.51
model_cnn_classify_fold_5_epoch_8_train_loss_0.2473_macro0.5571_full__0.97_0.25_0.46_test_loss_0.2387_macro0.6128_full__0.97_0.36_0.51
model_cnn_classify_fold_5_epoch_9_train_loss_0.24_macro0.5734_full__0.97_0.29_0.46_test_loss_0.2354_macro0.6141_full__0.97_0.36_0.51
model_cnn_classify_fold_5_epoch_10_train_loss_0.2327_macro0.5728_full__0.97_0.29_0.46_test_loss_0.234_macro0.6221_full__0.97_0.38_0.51
model_cnn_classify_fold_5_epoch_11_train_loss_0.2267_macro0.5912_full__0.97_0.34_0.47_test_loss_0.2269_macro0.6321_full__0.97_0.37_0.55
model_cnn_classify_fold_5_epoch_12_train_loss_0.217_macro0.6312_full__0.97_0.39_0.53_test_loss_0.2203_macro0.6382_full__0.97_0.43_0.52
model_cnn_classify_fold_5_epoch_13_train_loss_0.2154_macro0.6189_full__0.97_0.39_0.5_test_loss_0.2122_macro0.6391_full__0.97_0.42_0.53
model_cnn_classify_fold_5_epoch_14_train_loss_0.2079_macro0.618_full__0.97_0.4_0.48_test_loss_0.214_macro0.6573_full__0.97_0.49_0.51
model_cnn_classify_fold_5_epoch_15_train_loss_0.2008_macro0.6335_full__0.97_0.42_0.51_test_loss_0.2099_macro0.6431_full__0.97_0.44_0.51
model_cnn_classify_fold_5_epoch_16_train_loss_0.1962_macro0.6433_full__0.97_0.43_0.53_test_loss_0.2065_macro0.6542_full__0.97_0.46_0.53
model_cnn_classify_fold_5_epoch_17_train_loss_0.1886_macro0.6532_full__0.97_0.46_0.52_test_loss_0.2005_macro0.6509_full__0.97_0.45_0.53
model_cnn_classify_fold_5_epoch_18_train_loss_0.1862_macro0.6709_full__0.98_0.49_0.54_test_loss_0.1983_macro0.6587_full__0.97_0.47_0.54
model_cnn_classify_fold_5_epoch_19_train_loss_0.1798_macro0.6616_full__0.98_0.47_0.54_test_loss_0.1971_macro0.6565_full__0.97_0.45_0.54
model_cnn_classify_fold_5_epoch_20_train_loss_0.1745_macro0.6841_full__0.98_0.51_0.57_test_loss_0.1935_macro0.6676_full__0.97_0.46_0.57
model_cnn_classify_fold_5_epoch_21_train_loss_0.1702_macro0.6859_full__0.98_0.51_0.57_test_loss_0.1908_macro0.671_full__0.97_0.46_0.57
model_cnn_classify_fold_5_epoch_22_train_loss_0.1686_macro0.6885_full__0.98_0.52_0.57_test_loss_0.19_macro0.6745_full__0.97_0.48_0.56
model_cnn_classify_fold_5_epoch_23_train_loss_0.1571_macro0.7109_full__0.98_0.54_0.61_test_loss_0.1892_macro0.6777_full__0.97_0.49_0.57
model_cnn_classify_fold_5_epoch_24_train_loss_0.1549_macro0.7088_full__0.98_0.55_0.6_test_loss_0.19_macro0.6825_full__0.97_0.5_0.57
model_cnn_classify_fold_5_epoch_25_train_loss_0.1502_macro0.718_full__0.98_0.56_0.61_test_loss_0.189_macro0.6779_full__0.98_0.49_0.57
model_cnn_classify_fold_5_epoch_26_train_loss_0.1513_macro0.7283_full__0.98_0.57_0.64_test_loss_0.1906_macro0.6732_full__0.97_0.5_0.54
model_cnn_classify_fold_5_epoch_27_train_loss_0.1458_macro0.7174_full__0.98_0.58_0.59_test_loss_0.1907_macro0.6742_full__0.97_0.5_0.55
model_cnn_classify_fold_5_epoch_28_train_loss_0.1352_macro0.7435_full__0.98_0.62_0.63_test_loss_0.1926_macro0.6625_full__0.97_0.48_0.54
model_cnn_classify_fold_5_epoch_29_train_loss_0.1317_macro0.7428_full__0.98_0.62_0.63_test_loss_0.1936_macro0.6599_full__0.97_0.47_0.54
model_cnn_classify_fold_5_epoch_30_train_loss_0.1317_macro0.745_full__0.98_0.61_0.64_test_loss_0.1935_macro0.6647_full__0.97_0.48_0.54
model_cnn_classify_fold_5_epoch_31_train_loss_0.1267_macro0.7617_full__0.98_0.64_0.66_test_loss_0.1948_macro0.6666_full__0.97_0.48_0.55
model_cnn_classify_fold_5_epoch_32_train_loss_0.1206_macro0.7775_full__0.98_0.65_0.7_test_loss_0.197_macro0.6748_full__0.97_0.5_0.55
model_cnn_classify_fold_5_epoch_33_train_loss_0.1201_macro0.7654_full__0.98_0.65_0.66_test_loss_0.1989_macro0.6631_full__0.97_0.47_0.54
model_cnn_classify_fold_5_epoch_34_train_loss_0.1198_macro0.7681_full__0.98_0.64_0.68_test_loss_0.2006_macro0.676_full__0.97_0.5_0.56
model_cnn_classify_fold_5_epoch_35_train_loss_0.1134_macro0.7831_full__0.99_0.67_0.69_test_loss_0.2037_macro0.6671_full__0.97_0.49_0.54
model_cnn_classify_fold_5_epoch_36_train_loss_0.1122_macro0.7725_full__0.99_0.66_0.68_test_loss_0.2056_macro0.6666_full__0.97_0.48_0.55
model_cnn_classify_fold_5_epoch_37_train_loss_0.1071_macro0.7875_full__0.99_0.68_0.7_test_loss_0.2084_macro0.6649_full__0.97_0.47_0.55
model_cnn_classify_fold_5_epoch_38_train_loss_0.1039_macro0.7891_full__0.99_0.68_0.7_test_loss_0.2121_macro0.6628_full__0.97_0.48_0.53
model_cnn_classify_fold_5_epoch_39_train_loss_0.1057_macro0.8008_full__0.99_0.69_0.72_test_loss_0.2136_macro0.6726_full__0.97_0.48_0.57