
model_cnn_classify_fold_3_epoch_0_train_loss_0.7169_macro0.3211_full__0.87_0.06_0.04_test_loss_0.3364_macro0.326_full__0.96_0.0_0.02
model_cnn_classify_fold_3_epoch_1_train_loss_0.4305_macro0.3514_full__0.94_0.04_0.07_test_loss_0.2922_macro0.3826_full__0.96_0.05_0.14
model_cnn_classify_fold_3_epoch_2_train_loss_0.3628_macro0.4205_full__0.95_0.1_0.21_test_loss_0.264_macro0.4852_full__0.96_0.11_0.38
model_cnn_classify_fold_3_epoch_3_train_loss_0.3285_macro0.4604_full__0.96_0.13_0.3_test_loss_0.2517_macro0.5225_full__0.96_0.18_0.42
model_cnn_classify_fold_3_epoch_4_train_loss_0.3046_macro0.4886_full__0.96_0.16_0.35_test_loss_0.2463_macro0.5645_full__0.97_0.28_0.45
model_cnn_classify_fold_3_epoch_5_train_loss_0.2957_macro0.489_full__0.96_0.18_0.33_test_loss_0.2441_macro0.6061_full__0.97_0.36_0.48
model_cnn_classify_fold_3_epoch_6_train_loss_0.2813_macro0.5111_full__0.96_0.2_0.37_test_loss_0.2407_macro0.6351_full__0.97_0.42_0.51
model_cnn_classify_fold_3_epoch_7_train_loss_0.2613_macro0.5528_full__0.96_0.26_0.43_test_loss_0.2352_macro0.643_full__0.97_0.42_0.54
model_cnn_classify_fold_3_epoch_8_train_loss_0.2554_macro0.5578_full__0.97_0.3_0.4_test_loss_0.2324_macro0.6412_full__0.97_0.42_0.53
model_cnn_classify_fold_3_epoch_9_train_loss_0.2416_macro0.5778_full__0.97_0.34_0.43_test_loss_0.2279_macro0.6575_full__0.97_0.46_0.54
model_cnn_classify_fold_3_epoch_10_train_loss_0.237_macro0.5905_full__0.97_0.35_0.45_test_loss_0.2218_macro0.6646_full__0.97_0.47_0.55
model_cnn_classify_fold_3_epoch_11_train_loss_0.2292_macro0.5938_full__0.97_0.38_0.43_test_loss_0.2214_macro0.6672_full__0.97_0.5_0.53
model_cnn_classify_fold_3_epoch_12_train_loss_0.2196_macro0.6076_full__0.97_0.38_0.47_test_loss_0.2103_macro0.6651_full__0.97_0.48_0.54
model_cnn_classify_fold_3_epoch_13_train_loss_0.2158_macro0.6223_full__0.97_0.42_0.47_test_loss_0.213_macro0.6807_full__0.97_0.51_0.56
model_cnn_classify_fold_3_epoch_14_train_loss_0.2075_macro0.6336_full__0.97_0.43_0.5_test_loss_0.2095_macro0.6714_full__0.97_0.51_0.53
model_cnn_classify_fold_3_epoch_15_train_loss_0.2024_macro0.6372_full__0.97_0.44_0.5_test_loss_0.203_macro0.6753_full__0.98_0.51_0.54
model_cnn_classify_fold_3_epoch_16_train_loss_0.2015_macro0.6344_full__0.97_0.45_0.49_test_loss_0.2014_macro0.6893_full__0.97_0.51_0.58
model_cnn_classify_fold_3_epoch_17_train_loss_0.1878_macro0.6571_full__0.97_0.48_0.52_test_loss_0.1965_macro0.692_full__0.98_0.52_0.58
model_cnn_classify_fold_3_epoch_18_train_loss_0.1835_macro0.6712_full__0.98_0.49_0.54_test_loss_0.1924_macro0.696_full__0.98_0.54_0.57
model_cnn_classify_fold_3_epoch_19_train_loss_0.1903_macro0.6566_full__0.97_0.5_0.5_test_loss_0.1925_macro0.6822_full__0.98_0.53_0.54
model_cnn_classify_fold_3_epoch_20_train_loss_0.1765_macro0.6694_full__0.98_0.5_0.53_test_loss_0.1914_macro0.69_full__0.98_0.55_0.54
model_cnn_classify_fold_3_epoch_21_train_loss_0.1701_macro0.6808_full__0.98_0.53_0.54_test_loss_0.1893_macro0.6908_full__0.98_0.55_0.55
model_cnn_classify_fold_3_epoch_22_train_loss_0.1651_macro0.6949_full__0.98_0.53_0.57_test_loss_0.1888_macro0.7019_full__0.98_0.55_0.58
model_cnn_classify_fold_3_epoch_23_train_loss_0.1604_macro0.6971_full__0.98_0.55_0.56_test_loss_0.1876_macro0.7024_full__0.98_0.56_0.57
model_cnn_classify_fold_3_epoch_24_train_loss_0.1549_macro0.7136_full__0.98_0.57_0.59_test_loss_0.1885_macro0.6993_full__0.98_0.55_0.58
model_cnn_classify_fold_3_epoch_25_train_loss_0.1508_macro0.7066_full__0.98_0.57_0.58_test_loss_0.1912_macro0.7108_full__0.98_0.56_0.6
model_cnn_classify_fold_3_epoch_26_train_loss_0.145_macro0.7245_full__0.98_0.59_0.6_test_loss_0.1888_macro0.7163_full__0.98_0.54_0.63
model_cnn_classify_fold_3_epoch_27_train_loss_0.1429_macro0.7228_full__0.98_0.61_0.58_test_loss_0.1897_macro0.7149_full__0.98_0.55_0.62
model_cnn_classify_fold_3_epoch_28_train_loss_0.1403_macro0.7311_full__0.98_0.6_0.61_test_loss_0.1893_macro0.7254_full__0.98_0.57_0.63
model_cnn_classify_fold_3_epoch_29_train_loss_0.135_macro0.7376_full__0.98_0.62_0.61_test_loss_0.19_macro0.723_full__0.98_0.57_0.62
model_cnn_classify_fold_3_epoch_30_train_loss_0.1301_macro0.7476_full__0.98_0.63_0.63_test_loss_0.1909_macro0.7295_full__0.98_0.59_0.62
model_cnn_classify_fold_3_epoch_31_train_loss_0.1273_macro0.76_full__0.98_0.65_0.65_test_loss_0.1914_macro0.7275_full__0.98_0.58_0.63
model_cnn_classify_fold_3_epoch_32_train_loss_0.1234_macro0.7673_full__0.98_0.65_0.67_test_loss_0.1918_macro0.7239_full__0.98_0.56_0.64
model_cnn_classify_fold_3_epoch_33_train_loss_0.1217_macro0.7753_full__0.98_0.67_0.67_test_loss_0.1943_macro0.7133_full__0.97_0.56_0.61
model_cnn_classify_fold_3_epoch_34_train_loss_0.1181_macro0.7661_full__0.98_0.67_0.64_test_loss_0.1945_macro0.7201_full__0.97_0.55_0.63
model_cnn_classify_fold_3_epoch_35_train_loss_0.1166_macro0.7744_full__0.99_0.66_0.67_test_loss_0.1956_macro0.7132_full__0.97_0.53_0.63
model_cnn_classify_fold_3_epoch_36_train_loss_0.1123_macro0.7818_full__0.99_0.68_0.68_test_loss_0.1961_macro0.7246_full__0.97_0.56_0.64
model_cnn_classify_fold_3_epoch_37_train_loss_0.1096_macro0.787_full__0.99_0.68_0.69_test_loss_0.1975_macro0.714_full__0.97_0.54_0.63
model_cnn_classify_fold_3_epoch_38_train_loss_0.1089_macro0.7873_full__0.99_0.7_0.68_test_loss_0.1984_macro0.712_full__0.97_0.54_0.62
model_cnn_classify_fold_3_epoch_39_train_loss_0.1067_macro0.7932_full__0.99_0.69_0.7_test_loss_0.1997_macro0.7207_full__0.98_0.55_0.64